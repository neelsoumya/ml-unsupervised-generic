{
  "hash": "9694dcf997a25dbd01abd94c3509b7bb",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Introduction to Unsupervised Learning\"\nformat: html\n---\n\n::: {.callout-tip}\n## Learning Objectives\n\nBy the end of this module, learners will be able to:\n\n* Define unsupervised learning and explain how it differs from supervised learning in terms of inputs, outputs, and goals.\n\n* Identify common unsupervised techniques, including clustering (e.g., k‑means, hierarchical) and dimensionality reduction (e.g., PCA), and describe when each is appropriate.\n\n* Discuss real‑world applications of unsupervised learning, such as customer segmentation, anomaly detection, and image compression.\n\n* Explain the role of unsupervised learning in exploratory data analysis.\n\n* Interpret principal component analysis (PCA) intuitively to understand how PCA finds the directions of greatest variance in data.\n\n* Apply dimensionality reduction to a simple multivariate dataset (e.g., crime rates and population by state) to visualize high‑dimensional data in two or three dimensions.\n\n* Differentiate unsupervised from supervised problems by examining datasets and deciding whether the task is to uncover patterns versus predict a known target variable.\n\n* Articulate the value of unsupervised learning in uncovering hidden structure in unlabelled data and its importance as data complexity grow.\n:::\n\n\n## Setup instructions\n\n* Please go through the setup instructions [here](https://cambiotraining.github.io/ml-unsupervised/setup.html)\n\n* Walkthrough of getting setup with [Google Colab](https://colab.research.google.com/) in the web browser.\n\n\n## Poll\n\nWhat would you like to get out this course? \n\n<!--\nPlease click the link below and let me know your thoughts.\n\n* [Poll](https://docs.google.com/document/d/140c9hqnLHyUKF3o03KSJJPk8_OKQFSiKm63EqRMfHvs/edit?usp=sharing)\n\n-->\n\n\n## Introduction\n\nUnsupervised learning is a branch of machine learning that deals with finding hidden patterns or intrinsic structures in data without the use of labeled responses. Unlike supervised learning, where the model learns from labeled data to predict outcomes, unsupervised learning works with input data that does not have any corresponding output variables. The primary goal is to explore the underlying structure, groupings, or features in the data.\n\nOne of the most common applications of unsupervised learning is clustering, where the algorithm groups similar data points together based on their characteristics. This is particularly useful in scenarios such as customer segmentation, anomaly detection, and image compression. Another key technique is dimensionality reduction, which aims to reduce the number of variables under consideration, making it easier to visualize and interpret large datasets.\n\nUnsupervised learning is valuable because it can reveal insights that may not be immediately apparent, uncovering relationships and patterns that might otherwise go unnoticed. It is commonly used in exploratory data analysis and as a preprocessing step for other algorithms. As data continues to grow in complexity and volume, unsupervised learning plays a critical role in making sense of unstructured information.\n\n### Motivation\n\nHere is a picture (taken by Soumya Banerjee) of a pavement in Cambridge the day after Valentine's Day. Why did this picture capture my attention? The starkness of the grey pavement contrasted with the bright red rose. It may have triggered some unsupervised learning mechanism in my brain that allows me to pick anomalies!\n\n![Rose after Valentine's Day (picture taken by Soumya Banerjee)](images/rose_after_valentines_day.png)\n\nUnsupervised learning is all about discovering structure in data without any explicit \"right answers\" to guide you. The rose‑on‑pavement photo is a perfect real‑world illustration of a few core ideas:\n\n* Anomaly (or Outlier) Detection\n- **What happened in your brain:**  \n  When you look at a uniform grey pavement, your visual system builds an internal \"model\" of what is normal: flat, texture‑repeating, monochrome. The bright red rose doesn’t fit that model, so it “pops,” drawing your attention.\n\n- **In machine learning:**  \n  Algorithms can learn a representation of “normal” data (e.g. patches of pavement) and then flag anything that deviates significantly (e.g. the rose) as an anomaly.\n\n- **Human vision analogy:**  \n  Early in the visual cortex, neurons respond to edges, color contrasts, textures. A red circle on grey evokes strong responses in “color” and “shape‑edge” channels.\n\n<!--\n- **ML counterpart:**  \n  Techniques like PCA or deep autoencoders learn low‑dimensional “features” (color histograms, texture filters). Dimensions where the rose is extreme (high red‑channel value) are exactly the ones that give us the “anomaly” score.\n-->\n\n<!--\n* Clustering & Pattern Discovery\nYou might not only notice the rose, but if there were lots of petals scattered around, your brain could start grouping (clustering) regions of similar color/shape.\n-->\n\n<!--\nUnsupervised algorithms would partition image patches into clusters—“pavement patches,” “rose petals,” maybe even “shadows.” Anything that doesn’t belong to a big cluster may again be flagged as rare.\n-->\n\n<!--\n* Dimensionality Reduction & Visualization\nIn a high‑dimensional feature space (e.g. each 10×10 pixel patch → a 300‑dim vector), you can’t “see” clusters easily. Algorithms like t‑SNE or UMAP compress that down to 2D so you can actually plot and see the rose‑patches separate from pavement.\n\nThis is why, for instance, visual analytics tools will show outliers as distant points on a scatterplot—just as you instantly spot the rose on the pavement.\n\n-->\n\n\n<!--### Resources -->\n\n<!--\n[PCA intuition](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)\n-->\n\n\n\n\n\n### Example\n\nGiven the data below, how should we reduce the number of features and/or visualize it? This is an **unsupervised** machine learning problem.\n\n::: {.callout-tip}\n**NOTE (IMPORTANT CONCEPT)**: The columns of this data are the *features*.\n:::\n<!-- end callout -->\n\n\n| State       | Murder (per 100k) | Robbery (per 100k) | Population     |\n|-------------|-------------------|--------------------|----------------|\n| California  | 9.1               | 45.3               | 39,512,223     |\n| Texas       | 7.8               | 38.6               | 28,995,881     |\n| Florida     | 5.9               | 31.7               | 21,477,737     |\n| New York    | 3.4               | 26.4               | 19,453,561     |\n| Illinois    | 6.4               | 35.1               | 12,671,821     |\n| Pennsylvania| 4.8               | 22.9               | 12,801,989     |\n\n\n::: {.callout-tip}\n**NOTE (IMPORTANT CONCEPT)**: Importantly, in unsupervised machine learning we are not trying to predict anything. For example, say in the data below we can try to predict the number of people who moved to that state last year. This would be a **supervised** machine learning problem [@Gareth2017].\n:::\n<!-- end callout -->\n\n\n| State        | Murder (per 100k) | Robbery (per 100k) | Population   | People Who Moved (per 100k) |\n|--------------|-------------------|--------------------|--------------|-----------------------------|\n| California   | 9.1               | 45.3               | 39,512,223   | 5,400                       |\n| Texas        | 7.8               | 38.6               | 28,995,881   | 4,100                       |\n| Florida      | 5.9               | 31.7               | 21,477,737   | 6,200                       |\n| New York     | 3.4               | 26.4               | 19,453,561   | 3,800                       |\n| Illinois     | 6.4               | 35.1               | 12,671,821   | 2,900                       |\n| Pennsylvania | 4.8               | 22.9               | 12,801,989   | 2,500                       |\n\n\n::: {.callout-tip}\n**NOTE (IMPORTANT CONCEPTS)**: \n\n* If there is a column in the table that we are trying to predict, this would be called a *label*. **Supervised** machine learning (such as linear regression) tries to predict the *label* given the *features* [@Gareth2017].\n\n* However in unsupervised machine learning, we only deal with features and do not try to predict anything. \n\n* Hence there are no *labels* in unsupervised machine learning.\n:::\n<!-- end callout -->\n\n\n::: {.callout-tip}\n**NOTE (IMPORTANT CONCEPTS)**: \n\n* The number of columns in the data, is called the _dimensions_ of the data.\n\n* For example, if there are 3 columns, this is 3-dimensional data.\n\n* We can visualize it in 3 dimensions in a 3D plot.\n\n* Hence the columns of the data or dimensions form a _co-ordinate system_. We can visualize it in a plot. The X axis would represent the value in the first column, the Y axis would represent the values in the second column, and so on.\n\n* How would you visualize a table that has 14 columns/dimensions?\n\n:::\n<!-- end callout -->\n\n\n## Curse of dimensionality\n\nHow would you visualize data that has 14 dimensions? How about 1 million dimensions (can happen in the age of big data)? \n\n* Would you remove one column at a time?\n\n* Would you plot each feature/column vs the other exhaustively? How many pairwise plots would you need to plot for exhaustive visualization?\n\n::: {.callout-hint collapse=”true”}\n\n::: {#28fa2584 .cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of pairwise plots for 5 features: 10\nNumber of pairwise plots for 14 features: 91\nNumber of pairwise plots for 1000000 features: 499999500000\n```\n:::\n:::\n\n\n::: {#891b8b8a .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](walkthrough_files/figure-html/cell-3-output-1.png){width=949 height=566}\n:::\n:::\n\n\n* You will have an exponential blowup! So this approach will not work.\n\n* We need something more principled.\n\n:::\n<!-- end callout -->\n\n\n\n::: {.callout-tip}\n**NOTE (IMPORTANT CONCEPT)** \n\n* It is not possible to exhaustively plot one feature vs. another _or_ remove any feature randomly. For example, in a dataset from patient healthcare records, we cannot just randomly throw away data on blood pressure.\n\n* This is why we use dimensionality reduction to _reduce_ the dimensions of the data. This yields fewer _new_ features.\n\n:::\n<!-- end callout -->\n\n\n\n\n## What PCA does to the data\n\n<!--\n[PCA in 3D](https://github.com/neelsoumya/python_machine_learning/blob/main/pca_intro_3D_view.ipynb)\n-->\n\n### Projection of 3D Data\n\nWe generate three clusters of synthetic 3‑dimensional points, compute the first two principal components using scikit‑learn’s PCA, and then create a two‑panel figure:\n\n1. **Left panel**: A 3D scatter of the original points, the best‐fit plane defined by the first two principal components, and projection lines from each point down onto that plane.  \n2. **Right panel**: A 2D scatter of the projected coordinates (the principal component scores) along the first two components, colored by cluster.\n\nUse this visualization to understand how PCA finds the plane that maximizes variance and how the data look when reduced to two dimensions.\n\n\n\n::: {#5d6e72b7 .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](walkthrough_files/figure-html/cell-5-output-1.png){width=758 height=950}\n:::\n:::\n\n\n* Play around with the figure below to get an intuition of what PCA does!\n\n::: {#2e21f037 .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        </script>\n        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.1.0.min\"</script>\n        \n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"2a049e76-03c7-4a94-aaa5-1848dd83260f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"2a049e76-03c7-4a94-aaa5-1848dd83260f\")) {                    Plotly.newPlot(                        \"2a049e76-03c7-4a94-aaa5-1848dd83260f\",                        [{\"marker\":{\"color\":{\"dtype\":\"i1\",\"bdata\":\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIC\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"opacity\":0.9,\"showscale\":false,\"size\":5},\"mode\":\"markers\",\"name\":\"Data\",\"x\":{\"dtype\":\"f8\",\"bdata\":\"2ILRYIgzzr\\u002fgFDOeltXOPwy1ZhZwzPC\\u002fpjXmQzBu+b\\u002f2ijcbytLzv4eaxhtFqfq\\u002fn5u\\u002fuKz9+r9Na0g6x4r1v+gt\\u002fuWoQ9E\\u002fRJoRP1p\\u002fAcCGhCDZVYX9v7xumNGr2A\\u002fAdG02cHWh6L\\u002f\\u002fsVm0HWsCwDD+Vvxwpg3AzRp1GS2BA8ACxVJGQ+kMwJpCj1M\\u002fz\\u002fm\\u002f6leomrc5AMAy+jM6Eyn7v+loePEyYQXAu1jFQG3PDcAKs1FupQoNwIAL\\u002fk07K\\u002f+\\u002fnhZbkweK67+3eYS2fXoFwNHIA0EPfgLAQpQy9zaW8b8cU27vPGDgv\\u002fFqrG58cAHALvxjVJaM+T9Vjo0gKNAHQHPT7AiBFQBAx60KM0Y3A0DKPi7YL1jnP2JpoUOJjA9AoLLebS9iD0DzEIBXlD8HQK+86BhCtvs\\u002fzf\\u002f5IhSF\\u002fT\\u002f5io1j6wIDQOQrgTVwnApAjuDpbZwJ+T9+MOhZe0IDQGahvfTuNfU\\u002fEsT921VpBUCgBj+RBSsDQBiF2MvfgwNAFrKWGleIEUCdxFM8pu8IQHp3jn176P4\\u002fVuMEYujG8j\\u002fskb+xWQMJQGGhpGiw\\u002fvg\\u002fxhqf72mYB0BtyExgQcEGQE2dhsMVgQlA2MRtFcGMAkBkPE2Oe+fuP8SU+aaa9\\u002fQ\\u002fG0f0E9an1r+OBIWXh8kBwLp6Ud2Nq\\u002fG\\u002flFyIEjCw+D+E4imn4Bykv2KWLO069cW\\u002fYIk9pk5OAUDvF4QV+qPOv41JNxz1e+Q\\u002f8DdP\\u002f\\u002fKd57+UiHiELyDtP7J8rXvP2d2\\u002f39qYo8xtkb8fJM+4uqKlv9NhanOOq92\\u002fBpArJPAxsD\\u002fCm7KWNh3jv0d1YI+Nkt+\\u002faChOJrl\\u002f8r+WJA1PVI8AwPAzQFXiZeS\\u002f0PUEegEP07+oRQ4582\\u002fyP4CHH1t5dve\\u002fNGQDcYUrwj9Npl2OYjvmP3Qwgja3U\\u002fm\\u002fVU5Z7tY34L9xQaCIAPv+v6vTGXTUorY\\u002f\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"U4nM+iyc2T\\u002faPbF8hOH9PzaE00msX8O\\u002f7eGqDQVwwj+Qs5MIGCa\\u002fPzuZTXW\\u002f5\\u002fc\\u002f8IV+lsBU679qkHIadqnrPw06DfEURfe\\u002fx4daf0OG+D8z6pCR0DPYP0Upz1ExRNa\\u002fJWD+pvI88z9TZFF538bwv8zKxUJgNv8\\u002fb+u\\u002fJXML9L+jygfREjvLvz+WDwSEWOC\\u002fQs\\u002fwE8pp2z\\u002f5re\\u002fYXUzkv6Zcf0PrAte\\u002fT7g3W+a1xj+Jvyl3OZ7dPyn+C7u1VOc\\u002fEc4quNjB87969aX7kd3rvz4\\u002fFyi0waw\\u002fnItn1WnN3T+TRH7jj1X+P57nN4DNIfG\\u002f4C7njyKP8z9KeVABtc7WP4t4Y\\u002fDskvw\\u002fTb0UoGIh\\u002fj9ZcMw+TAXvP8qM1767eNq\\u002fJkgnRzCw9z\\u002flH\\u002fkqKY\\u002frv2crDQm5rek\\u002fKByZx4mm4z8wF4xIJZfxvwnETGDmOea\\u002f+vY3kJWW\\u002fT\\u002fkCA0JJ6Pov1uAmk0YTKA\\u002flB+RlW5z4j8aOYgQLn3xvx8V3p2OVcU\\u002f4ruLCy057j9gYMvt9A31v7YtxQ7aafs\\u002f2amdRC80ub8jdOVCZkfxv919BIDD39+\\u002foT15FsJptj9n7d\\u002fO4QDwv2JEO6rJSNQ\\u002f5K0KCChr6z\\u002f44KROn8\\u002flP7\\u002fON81xJ92\\u002fmqclJWYA5D86vdRYeQAFQGJaa4bVagBAtpDKi+qg5j94AJFi+p7qP5uYRoagLAZAaifIkDWxCkC0iohUGswIQFxjp8vKg9g\\u002fmuSxG0k9AkB9iR+0qYkCQAQGoFKM4\\u002fA\\u002fHHKDtIAIA0C5veEDc7TwPy3le\\u002fUS2gNALF\\u002fxf4ZAAUDnavz7eDH8P6D\\u002fI3xwUPc\\u002faFVUyuQ\\u002fBkB+nGJW+mgDQBpdXU\\u002fGpPk\\u002fqnG+akgO+z8cnYcSD6MIQMir2w8kKwRAm9q64gfk+j8Z+NYA9GP0P4pYe5UO4gRAoFkraX919j9qUFtanoIBQDtsvDicBvs\\u002f\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"q8kiUtJR7z+CjKVC3EXvv1m0yPiMbLq\\u002f94X9S7RE9z\\u002fLdSJVQWjcP7ZqsECgQsq\\u002fOjqw7IVsBMDXL1zb0L\\u002fnv111pQ6pbac\\u002fDgBtV36C9z\\u002fKo\\u002f2nvWjsv+5OiDY+A8Q\\u002f+GBoa\\u002fbJ2L9drH66ZLj2vzarnhcST+C\\u002fUxxodDPh6D8ioV99qafsv66StpLe4\\u002fK\\u002ftafBzkUHsT96+DS5JjfXv2fWB1pLBeq\\u002fhe1KY8e22b+ssFeUlgjtv2UVuRODgsA\\u002fbkyrJ\\u002fe\\u002f2T\\u002fc1m6774Xiv32q0Sh0pPK\\u002fXvRzQnSU+L98LbX3R9zyP0wUJsYI3\\u002fA\\u002fVCa1JcGoyj9hsjNVP5zmPwSC0MunPsA\\u002fW+knzmuQ9b8aMzIMHcXyv2IHTFom6+e\\u002fWyQmgYXh\\u002fT\\u002fsvKxEoI\\u002f+P9kd1VvjT+4\\u002f9\\u002f\\u002fQkLeC7T+LjyiRVRbTP2yYh4A5J8O\\u002fbYBUS3CD5T8LxR+Fh0HhPy+r\\u002fd\\u002fZWOS\\u002fXqOAm4ipyr\\u002f0UOnrMNz3v4JFrHItUuQ\\u002f9war9NY17b9jCoEnmordvyyQhxAI1ee\\u002fBAGx0DY75b9up\\u002fQWCFzyv4WkuwBd3\\u002f4\\u002fw7dLRmKb879MdMflYbf4v4Pki+ysd+0\\u002f+6gCoDPV5L\\u002f8Vx0viLXpv8guf4EO5pE\\u002f6KmLML2z9T+kNLcq43fZP0Ku0v2\\u002fKvQ\\u002f7sjxkOsiAkCq832sqy8EQK4ni1iJlgZAGCn8yNQX+j8Gqy3p+j0FQFFKtDVcnP8\\u002fKk1m2\\u002flt\\u002fj\\u002fNgYlQZkoGQBFdn7tvcPk\\u002f8RsbSYgJEUD9vkXQ23b6P7zlS+uUY90\\u002fRdopu4HbAUBKDg3RF27iP3GJ8QsSVANAO74XULT0C0AS1obCTmoFQNLYj5243\\u002f0\\u002fwNb1h1q81D8QuS\\u002fCdfzyP\\u002fWPw42SyfY\\u002f5hr+d0WIBUD6naODe7vjPxaqCG7d9Ok\\u002fNe7aMa8o\\u002fz92SfDG7TAEQL\\u002f+Bb15xwBA\"},\"type\":\"scatter3d\"},{\"colorscale\":[[0.0,\"rgb(255,255,255)\"],[0.125,\"rgb(240,240,240)\"],[0.25,\"rgb(217,217,217)\"],[0.375,\"rgb(189,189,189)\"],[0.5,\"rgb(150,150,150)\"],[0.625,\"rgb(115,115,115)\"],[0.75,\"rgb(82,82,82)\"],[0.875,\"rgb(37,37,37)\"],[1.0,\"rgb(0,0,0)\"]],\"name\":\"PC1-PC2 plane\",\"opacity\":0.25,\"showscale\":false,\"x\":{\"dtype\":\"f8\",\"bdata\":\"VclwzjNkEcBgDdmW\\u002fbgLwBWI0JCTqQTAlgWQFVM0+78D9v0S\\u002firqv1D5IClQlbA\\u002fUDRGHVJQ7j+6JLQa\\u002fUb9P6mXYpPosgVA9BxrmVLCDEAcOHjcBv8QwO\\u002fq57Kj7grApGXfrDnfA8CzwK1Nn5\\u002f5vz5sOYOWAee\\u002fvqOiU0bwxD8LX4XW3LzwP51pluKw2\\u002f4\\u002fGrpTd0J9BkBlP1x9rIwNQOSmf+rZmRDAfcj2zkkkCsAyQ+7I3xQDwNF7y4XrCvi\\u002feOJ08y7Y479pZVpJ8srQP+2jZ56QUfI\\u002fQFc8VTI4AECM3ERbnEcHQNdhTWEGVw5AqxWH+Kw0EMAMpgXr71kJwMEg\\u002feSFSgLA7jbpvTd29r+zWLBjx67gv\\u002fR442jBHdc\\u002f0OhJZkTm8z+xeS05jAIBQP3+NT\\u002f2EQhASIQ+RWAhD0DlCB0NAJ8PwJuDFAeWjwjAUP4LASyAAcAL8gb2g+H0v9yd16e\\u002fCtu\\u002ffoxsiJBw3T+zLSwu+Hr1PyKcHh3mzAFAbiEnI1DcCEC5pi8puusPQHPmKymm1A7AKWEjIzzFB8De2xod0rUAwCmtJC7QTPO\\u002fUIpOiPC31L8F0PrTr+HhP5VyDvarD\\u002fc\\u002flL4PAUCXAkDgQxgHqqYJQJVkkAYKWxBAAsQ6RUwKDsC4PjI\\u002f4voGwNpyU3Lw1v+\\u002fRmhCZhy48b+N7YrRQsrMv8pZv2MXC+U\\u002feLfwvV+k+D8F4QDlmWEDQFFmCesDcQpAzvWI+DbAEECRoUlh8j8NwEccQVuIMAbA+C1xqjxC\\u002fr9kI2CeaCPwv3rGeJKkJMC\\u002fjuOD83406D9a\\u002fNKFEzn6P3YD8sjzKwRAwoj6zl07C0AHh4HqYyURQB9\\u002fWH2YdQzA1flPdy5mBcAV6Y7iiK38vwK9+6xpHe2\\u002fEPs0mzL4m79UbUiD5l3rPz1BtU3Hzfs\\u002f6CXjrE32BEA0q+uytwUMQD8YetyQihFArlxnmT6rC8Bk116T1JsEwDKkrBrVGPu\\u002fPDM3HQL06b9oD1fXL02yPxr3DBNOh+4\\u002fIIaXFXti\\u002fT9ZSNSQp8AFQKXN3JYR0AxAeKlyzr3vEUA=\",\"shape\":\"10, 10\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"hUSDR5tK9b8S7WT9scb2v5+VRrPIQvi\\u002fLD4oad+++b+55gkf9jr7v0aP69QMt\\u002fy\\u002f0zfNiiMz\\u002fr9g4K5AOq\\u002f\\u002fv3ZESHuolQDAvRg51rNTAcCQFW8X66nov6pmMoMYouu\\u002fxLf17kWa7r9vhFytOcnwv\\u002fwsPmNQRfK\\u002fidUfGWfB878WfgHPfT31v6Im44SUufa\\u002fMM\\u002fEOqs1+L+9d6bwwbH5v2CIXn9++sq\\u002fZOY1F5pt07+YiLzu9F3Zv8wqQ8ZPTt+\\u002fgObkTlWf4r+aN6i6gpflv7SIayawj+i\\u002fzdkukt2H67\\u002fnKvL9CoDuvwG+2jQcvPC\\u002fxKJ\\u002fr1dZ1j+QAPnX\\u002fGjQP7i85ABE8cQ\\u002foPCuoxwhsj\\u002fAYK7pOoGWvwAhhhi6Yb2\\u002f6FRQu5KRyr+mzC41JDnTv9putQx\\u002fKdm\\u002fDxE85NkZ37\\u002fcRFdP9xftP8Lzk+PJH+o\\u002fqKLQd5wn5z+OUQ0Mby\\u002fkP3QASqBBN+E\\u002ftF4NaSh+3D+AvIaRzY3WP04aALpyndA\\u002fNPDyxC9axT+UV8sr9PKyPyxcd2Ohgfc\\u002fn7OVrYoF9j8SC7T3c4n0P4Vi0kFdDfM\\u002f+Lnwi0aR8T9rEQ\\u002fWLxXwP7zRWkAyMu0\\u002fo4CX1AQ66j+JL9Ro10HnP27eEP2pSeQ\\u002f9Iqhj6M7AEBabWFpMPv+P87Ef7MZf\\u002f0\\u002fQBye\\u002fQID\\u002fD+0c7xH7Ib6PybL2pHVCvk\\u002fmiL5276O9z8NehcmqBL2P4DRNXCRlvQ\\u002f8yhUunoa8z\\u002fSZ4dtdrYEQIuTlhJr+ANARL+lt186A0D+6rRcVHwCQLgWxAFJvgFAcULTpj0AAUAqbuJLMkIAQMgz4+FNCP8\\u002fPIsBLDeM\\u002fT+u4h92IBD8P7BEbUtJMQlAanB88D1zCEAknIuVMrUHQN3Hmjon9wZAlvOp3xs5BkBQH7mEEHsFQApLyCkFvQRAw3bXzvn+A0B9ouZz7kADQDbO9RjjggJAkCFTKRysDUBJTWLOEO4MQAJ5cXMFMAxAvKSAGPpxC0B20I+97rMKQC\\u002f8nmLj9QlA6CeuB9g3CUCiU72szHkIQFx\\u002fzFHBuwdAFavb9rX9BkA=\",\"shape\":\"10, 10\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"DOsP5XeVAsDMqJQjFv8CwI1mGWK0aAPATSSeoFLSA8AN4iLf8DsEwM6fpx2PpQTAjl0sXC0PBcBOG7Gay3gFwA7ZNdlp4gXAz5a6FwhMBsBgb2rbdTz6v+Hqc1iyD\\u002fu\\u002fYmZ91e7i+7\\u002fi4YZSK7b8v2JdkM9nif2\\u002f49iZTKRc\\u002fr9kVKPJ4C\\u002f\\u002fv\\u002fJnVqOOAQDAsiXb4SxrAMBz418gy9QAwE4Ratn3m+6\\u002fKIS+aTgh8L+o\\u002f8fmdPTwvyl70WOxx\\u002fG\\u002fqvba4O2a8r8qcuRdKm7zv6vt7dpmQfS\\u002fLGn3V6MU9b+s5ADV3+f1vy1gClIcu\\u002fa\\u002fvIf+9wd+0b\\u002fAdSTs+crUv8JjSuDrF9i\\u002fxFFw1N1k27\\u002fGP5bIz7Hev+QWXt5g\\u002f+C\\u002f5g1x2Nml4r\\u002fnBITSUkzkv+j7lszL8uW\\u002f6vKpxkSZ578kE9fC3zvaPyAlsc7t7tY\\u002fHjeL2vuh0z8cSWXmCVXQPzS2fuQvEMo\\u002fLtoy\\u002fEt2wz9U\\u002fM0n0Li5P5CIbK4QCqk\\u002fAHguLO\\u002fXZb+YV\\u002fKTDsWrv4Mra99xffE\\u002fArBhYjWq8D8DabDK8a3vPwJyndB4B+4\\u002fAXuK1v9g7D8AhHfchrrqP\\u002f6MZOINFOk\\u002f\\u002fZVR6JRt5z\\u002f8nj7uG8flP\\u002fqnK\\u002fSiIOQ\\u002fOpIgzutr\\u002fD+5FhdRr5j7PzibDdRyxfo\\u002fuB8EVzby+T84pPrZ+R75P7co8Vy9S\\u002fg\\u002fNq3n34B49z+2Md5iRKX2PzW21OUH0vU\\u002ftDrLaMv+9D94\\u002fGreMq0DQLg+5p+UQwNA94BhYfbZAkA3w9wiWHACQHcFWOS5BgJAtkfTpRudAUD2iU5nfTMBQDbMySjfyQBAdg5F6kBgAEBqoYBXRe3\\u002fP9WvxdVvJAlAFPJAl9G6CEBUNLxYM1EIQJR2NxqV5wdA1Liy2\\u002fZ9B0AT+y2dWBQHQFM9qV66qgZAk38kIBxBBkDSwZ\\u002fhfdcFQBIEG6PfbQVAMmMgzaybDkBypZuODjIOQLHnFlBwyA1A8SmSEdJeDUAxbA3TM\\u002fUMQHCuiJSViwxAsPADVvchDEDwMn8XWbgLQDB1+ti6TgtAb7d1mhzlCkA=\",\"shape\":\"10, 10\"},\"type\":\"surface\"},{\"line\":{\"color\":\"rgba(120,120,120,0.7)\",\"width\":2},\"mode\":\"lines\",\"name\":\"Projections\",\"x\":[-0.23594765403233597,-0.2100947664301153,null,0.2408931992014578,0.1620538428715118,null,-1.0499115824744107,-1.0340762389623372,null,-1.5894014980616276,-1.53911771645763,null,-1.2389622748530065,-1.2167188927856023,null,-1.6663256726257332,-1.7074758092170463,null,-1.6869322983490986,-1.7144390892409305,null,-1.3463814045596394,-1.3819186255898204,null,0.26975462398760763,0.33102875959552225,null,-2.187183850025834,-2.182032784573286,null,-1.8450525743030837,-1.8673410072335894,null,-3.980796468223927,-3.945532854953035,null,-0.769709319272279,-0.8078335806895276,null,-2.3023027505753357,-2.290561695150845,null,-3.7062701906250126,-3.767357113899091,null,-2.4380743016111865,-2.358041798709165,null,-3.6138978475579515,-3.613155526497812,null,-1.613097502140738,-1.6140898290577272,null,-2.028182228338655,-2.025246066024995,null,-1.6975281022602187,-1.6714412173840607,null,-2.672460447775951,-2.6662876190472353,null,-3.726282602331677,-3.724703237929904,null,-3.6301983469660444,-3.652467441961,null,-1.9480546042038611,-1.9536451987980694,null,-0.8605993154566993,-0.7946240313291008,null,-2.684810090940313,-2.6549026812355763,null,-2.3115525321273727,-2.329844002503756,null,-1.099173513045813,-1.1438768117429061,null,-0.5117478062044003,-0.530091779280531,null,-2.179924835812351,-2.098797076724804,null,1.5968230530268204,1.5700845647625898,null,2.976639036483713,2.990256482390158,null,2.0105000207208206,1.9617630864008413,null,2.401989363444702,2.308188556491464,null,0.7295150015142664,0.6744908272696467,null,3.9436211856492926,3.940811005679845,null,3.922942026480385,3.9292703043162978,null,2.9060446582753854,2.9942339095295476,null,1.7319966290486197,1.7396899956205054,null,1.8449899069091658,1.8581043094091862,null,2.3764255311556295,2.42877070513383,null,3.3263858966870306,3.3508399450787985,null,1.5648464482783626,1.5300088026957601,null,2.4074618362411107,2.4553776972713957,null,1.325667339342624,1.3159835931216368,null,2.6764332949464995,2.6577547961422603,null,2.396006712661645,2.398292900192826,null,2.4393917012645367,2.458421486985108,null,4.383144774863942,4.3292292203740335,null,3.117016288095853,3.15407864771433,null,1.9317583946753687,1.8613485824838802,null,1.1735614613409857,1.1677794879448162,null,3.126635922106507,3.1366549043493945,null,1.562179955255566,1.6412646211432285,null,2.949420806925761,2.918353489164547,null,2.844362976401547,2.84118203886471,null,3.1880297923523018,3.2085336543078036,null,2.3187276529430214,2.2789866532399103,null,0.9657571582155353,0.93024938423532,null,1.3104502222497993,1.3353667357549943,null,-0.35399391125348395,-0.3249659963925272,null,-2.223403152224427,-2.284736240681888,null,-1.1043833394284506,-1.124577696077032,null,1.5430145954067358,1.591008456025335,null,-0.0392828182274956,0.014668256094272053,null,-0.1715463312222481,-0.17421135794333797,null,2.16323594928069,2.103928859828399,null,-0.2393791775759264,-0.25762148518755845,null,0.640131526097592,0.6926359951542477,null,-0.7380309092056887,-0.74872963768997,null,0.9101789080925919,0.9196984035634419,null,-0.46641909673594306,-0.44515041475635375,null,-0.017020413861440594,0.03318524760916227,null,-0.04225715166064269,-0.019628266954477683,null,-0.4635959746460944,-0.5217498805915814,null,0.06326199420033171,0.06437777650956535,null,-0.5973160689653627,-0.6277768952173669,null,-0.49331988336219407,-0.46250891124199967,null,-1.1561824318219127,-1.1386082847050334,null,-2.0699850250135325,-2.0614886093278275,null,-0.637437025552229,-0.6265249599945141,null,-0.2977908794017283,-0.3334456784693568,null,1.15233156478312,1.0912289952675154,null,-1.466424327802514,-1.4971350069939482,null,0.14195316332077967,0.17170348148845022,null,0.6947491436560057,0.6793518690650675,null,-1.5829383973350817,-1.633493803164,null,-0.5068163542986875,-0.4872257744123243,null,-1.936279805846507,-1.9243128275134176,null,0.08842208704466141,0.10145360201508674,null],\"y\":[0.4001572083672233,0.8555317211341682,null,1.8675579901499675,0.4788762294121556,null,-0.1513572082976979,0.12756760456105032,null,0.144043571160878,1.0297455051310362,null,0.12167501649282841,0.5134714543639738,null,1.4940790731576061,0.7692577808949697,null,-0.8540957393017248,-1.3386022166003788,null,0.8644361988595055,0.23848118135037,null,-1.4543656745987648,-0.3750789010287229,null,1.5327792143584575,1.623510430026743,null,0.37816251960217356,-0.014427447222104539,null,-0.3479121493261526,0.27322352258443666,null,1.2023798487844115,0.5308565267247204,null,-1.0485529650670926,-0.8417452198139882,null,1.9507753952317897,0.8747861923864001,null,-1.2527953600499264,0.15690256519833345,null,-0.2127402802139687,-0.19966498679688038,null,-0.510805137568873,-0.5282840510767953,null,0.42833187053041766,0.48004963233560494,null,-0.6343220936809636,-0.17482593708654715,null,-0.3595531615405413,-0.2508245383405808,null,0.17742614225375283,0.20524517376793916,null,0.4627822555257742,0.07053290840769055,null,0.7290905621775369,0.6306174504468274,null,-1.2348258203536526,-0.07273269843541674,null,-0.8707971491818818,-0.34400600956286753,null,0.05616534222974544,-0.2660218555253392,null,0.46566243973045984,-0.32174449045381615,null,1.8958891760305832,1.5727771921671108,null,-1.0707526215105427,0.3582372203511663,null,1.2224450703824274,0.7514715275893656,null,0.3563663971744019,0.596225011430108,null,1.7858704939058352,0.9274148327359465,null,1.8831506970562544,0.23093693197540055,null,0.9693967081580112,0.0001971772361774038,null,-0.41361898075974735,-0.46311768102351214,null,1.4805147914344245,1.591981505734243,null,-0.8612256850547025,0.6921457579749649,null,0.8024563957963949,0.937967875524055,null,0.6140793703460803,0.8450773439791415,null,-1.0994007905841947,-0.17738935175458637,null,-0.6945678597313655,-0.26383259553504457,null,1.8492637284793418,1.2356310802732493,null,-0.7699160744453164,0.0740771462036679,null,0.03183055827435118,-0.13873960336446367,null,0.5765908166149409,0.24758647392527056,null,-1.0930615087305058,-1.0527924467547893,null,0.16667349537252904,0.5018654295926774,null,0.9444794869904138,-0.005192740505480686,null,-1.315907410511521,-0.6630884986385172,null,1.7133427216493664,0.47313952214459865,null,-0.0984525244254323,-0.20029659533246869,null,-1.0799315083634233,-0.9034564767354892,null,-0.4980324506923049,0.8949702092054346,null,0.0875512413851909,-0.4596705972798897,null,-1.0002153473895647,-1.0562445965499254,null,0.3169426119248496,0.6780990247591743,null,0.8568306119026912,0.15682995220379836,null,0.681594518281627,0.05615818310448917,null,-0.45553250351734315,-0.016651347498836788,null,0.6250487065819812,1.1363483644706083,null,2.6252314510271875,1.5449062779734544,null,2.0521650792609742,1.6964603138598529,null,0.7071430902765516,1.5525102009555867,null,0.8319065022588026,1.7822043784781618,null,2.7717905512136674,2.72484859009506,null,3.336527949436392,2.2918888600434206,null,3.099659595887113,2.7783383543992555,null,0.3830439556891656,1.307861228816824,null,2.2799245990432384,2.091476471092652,null,2.317218215191302,2.4848952529955057,null,1.0555537440817497,1.43018174860758,null,2.379151735555082,3.2634776562059766,null,1.044054999507223,1.4426417069605177,null,2.4814814737734623,1.4571546367532897,null,2.1565065379653756,2.1761600031116686,null,1.762078270263993,1.2255392141086814,null,1.4571385239832821,1.9998450731698534,null,2.781198101709993,3.0907503190010366,null,2.426258730778101,2.5759151719723485,null,1.6027281856712023,1.7949340472786544,null,1.6909870309528778,1.0629609859307387,null,3.0796185920368213,2.0033537952337426,null,2.5210648764527583,1.9801248937043807,null,1.6806715828549048,2.2046957015030992,null,1.2744026215364157,1.003193984316908,null,2.610379379107205,1.7198930376471857,null,1.4036859615494919,1.7487557621781977,null,2.1887785967938287,2.3995657634565983,null,1.6891138283015283,1.9186518153758554,null],\"z\":[0.9787379841057392,0.6017716726368266,null,-0.977277879876411,0.17229511218386662,null,-0.10321885179355784,-0.3341172770076437,null,1.454273506962975,0.7210752673845371,null,0.44386323274542566,0.1195278694561483,null,-0.20515826376580087,0.3948604051714617,null,-2.5529898158340787,-2.1519075977707605,null,-0.7421650204064417,-0.22398943639732805,null,0.04575851730144607,-0.8476923514741321,null,1.469358769900285,1.3942500171118561,null,-0.8877857476301128,-0.5627934883703332,null,0.15634896910398005,-0.3578370834688249,null,-0.3873268174079523,0.1685709385820654,null,-1.4200179371789752,-1.5912166993529235,null,-0.5096521817516535,0.381068905189348,null,0.7774903558319103,-0.3894801536445043,null,-0.8954665611936756,-0.9062904983983837,null,-1.180632184122412,-1.1661628597117653,null,0.06651722238316789,0.02370443124413668,null,-0.3627411659871381,-0.7431194401972026,null,-0.813146282044454,-0.903153576896635,null,-0.4017809362082619,-0.4248099758328566,null,-0.9072983643832422,-0.5825880755690143,null,0.12898291075741067,0.21050052904139605,null,0.402341641177549,-0.5596576483547353,null,-0.5788496647644155,-1.0149358032047484,null,-1.1651498407833565,-0.898438120792129,null,-1.5362436862772237,-0.8844156243748271,null,1.1787795711596507,1.4462568438957144,null,1.0544517269311369,-0.12848893994989186,null,0.20827497807686035,0.5981544163163256,null,0.7065731681919482,0.5080143675673434,null,0.12691209270361992,0.8375554314897735,null,-1.3477590611424464,0.01996994282895087,null,-1.17312340511416,-0.3708045181192955,null,-0.7474548114407578,-0.7064789949692591,null,1.8675589604265699,1.7752850299295715,null,1.9100649530990337,0.6241592056253649,null,0.947251967773748,0.8350733955382523,null,0.9222066715665268,0.7309828510936978,null,0.298238174206056,-0.4650176547507646,null,-0.14963454032767076,-0.5062040873957898,null,0.6722947570124355,1.1802696864515319,null,0.5392491912918173,-0.1594219077111363,null,-0.635846078378881,-0.49464536802523074,null,-0.20829875557799488,0.06405630612141289,null,-1.4912575927056055,-1.524592966850861,null,0.6350314368921064,0.35755418787055815,null,-0.9128222254441586,-0.12666835282544586,null,-0.4615846048147089,-1.0019985506252027,null,-0.7447548220484399,0.28190524012443924,null,-0.6634782863621074,-0.5791701341084214,null,-1.1474686524111024,-1.2935575086690483,null,1.9295320538169858,0.7763821522615981,null,-1.225435518830168,-0.7724365206574593,null,-1.5447710967776116,-1.4983891873861153,null,0.920858823780819,0.6218877637136606,null,-0.6510255933001469,-0.07155384133684395,null,-0.8034096641738411,-0.2856634537024101,null,0.01747915902505673,-0.34583368769585954,null,1.3563815971671094,0.9331195552964525,null,0.3979423443932524,1.2922528168845058,null,1.2604370036086867,1.5548951026586895,null,2.267050869349183,1.567242442185624,null,2.523276660531754,1.7366048658841453,null,2.8235041539637313,2.862363460841662,null,1.6308181620575564,2.495587123218655,null,2.6552637307225977,2.9212585982532744,null,1.9756738756010643,1.2100953320955057,null,1.9018496103570421,2.05784998742055,null,2.786327962108976,2.6475222259797935,null,1.5899503067974516,1.2798272474699375,null,4.259308950690852,3.5272497969658216,null,1.6540182243006136,1.3240617671501345,null,0.4592029855553752,1.3071571390363648,null,2.232181036200276,2.2159115831323737,null,0.5759390910174684,1.0200947108147331,null,2.4160500462614256,1.9667888770014188,null,3.494484544491369,3.238232263593627,null,2.6769080350302454,2.553020037255034,null,1.8671194224130443,1.7080083332732203,null,0.3239961936700233,0.8438862074081617,null,1.186635740795797,2.077584968826783,null,1.4242120301869339,1.8720108074695683,null,2.691538751070186,2.2577431968849746,null,0.6166360446049446,0.8411468961015273,null,0.8111407422159711,1.548299590905048,null,1.9474327037304537,1.6617783987674324,null,2.5238910238342056,2.3493980329133164,null,2.0974001662687836,1.90738494604127,null],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"},\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":30}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"X\\u2081\"}},\"yaxis\":{\"title\":{\"text\":\"X\\u2082\"}},\"zaxis\":{\"title\":{\"text\":\"X\\u2083\"}},\"aspectmode\":\"data\"},\"margin\":{\"l\":0,\"r\":0,\"t\":40,\"b\":0},\"title\":{\"text\":\"Data and first two principal components\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('2a049e76-03c7-4a94-aaa5-1848dd83260f');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };            </script>        </div>\n```\n:::\n:::\n\n\n## Another intuition behind PCA\n\nPrincipal Component Analysis (PCA) reduces the number of dimensions in your data by finding the directions where the data varies the most and keeping only those directions.\n\nImagine you have a book: it has length, width, and height. But if the book is very thin, almost all of its *size* or *volume* is in the length and width—the height is so small that you can almost ignore it. If you wanted to describe where the book is on a table, you could just use two numbers (length and width), and you wouldn’t lose much information by ignoring the height.\n\nPCA works the same way: it finds the *thin* directions in your data that do not add much information, and lets you focus on the most important dimensions. This makes it easier to visualize and analyze your data without losing the main patterns.\n\n![A thin book on the floor. Image created using the DALL-E AI tool.](images/book_pca.png)\n\n::: {.callout-tip}\n**NOTE (IMPORTANT CONCEPT)** \n\nSay your data has too many *columns/dimensions/features*. Dimensionality reduction techniques (such as PCA) reduce the number of dimensions or the number of columns in your data.\n:::\n<!-- end callout -->\n\n\n## Coming back to the crime data\n\n* Original Data (4 Features)\n\nOur crime dataset has **4 features** (dimensions) for each state:\n\n| State        | Murder (per 100k) | Robbery (per 100k) | Population   | People Who Moved (per 100k) |\n|--------------|-------------------|--------------------|--------------|-----------------------------|\n| California   | 9.1               | 45.3               | 39,512,223   | 5,400                       |\n| Texas        | 7.8               | 38.6               | 28,995,881   | 4,100                       |\n| Florida      | 5.9               | 31.7               | 21,477,737   | 6,200                       |\n| New York     | 3.4               | 26.4               | 19,453,561   | 3,800                       |\n| Illinois     | 6.4               | 35.1               | 12,671,821   | 2,900                       |\n| Pennsylvania | 4.8               | 22.9               | 12,801,989   | 2,500                       |\n\n---\n\n## What PCA Does\n\nPCA finds **new features** (called Principal Components) that are combinations of the original features. These new features capture the most important patterns in the data.\n\n---\n\n## After PCA: Reduced to 2 New Features\n\nPCA transforms our data into **Principal Components (PC1 and PC2)**. These are the new, reduced features:\n\n| State        | PC1 (Primary Pattern) | PC2 (Secondary Pattern) | Variance Explained |\n|--------------|-----------------------|-------------------------|-------------------|\n| California   | 3.45                  | 0.82                    | PC1: 68%          |\n| Texas        | 2.18                  | -0.15                   | PC2: 23%          |\n| Florida      | 1.35                  | 1.24                    | **Total: 91%**    |\n| New York     | 0.92                  | -1.05                   |                   |\n| Illinois     | 0.31                  | 0.18                    |                   |\n| Pennsylvania | -0.22                 | -0.94                   |                   |\n\n---\n\n## What Did We Gain?\n\n### Before PCA:\n- **4 features** to track and visualize\n- Hard to see overall patterns\n- Features may be correlated (redundant information)\n\n### After PCA:\n- **2 features** capture 91% of the information\n- Easier to visualize (can plot in 2D)\n- New features are uncorrelated\n- Lost only 9% of information\n\n---\n\n## What Do the Principal Components Mean?\n\n**PC1 (Primary Pattern):** Combines all 4 original features with different weights. States with high PC1 values (like California) tend to have high values across multiple original features.\n\n**PC2 (Secondary Pattern):** Captures the remaining variation not explained by PC1. This might separate states based on different combinations of the original features.\n\n**Key Insight:** PC1 and PC2 are weighted combinations like:\n- PC1 = 0.45×Murder + 0.48×Robbery + 0.52×Population + 0.54×Migration\n- PC2 = 0.62×Murder - 0.15×Robbery - 0.68×Population + 0.35×Migration\n\n(These weights are determined by the data patterns, not chosen arbitrarily)\n\n\n\n\n## PCA is lossy \n\nPCA does lose some information. But it can capture some/most of the salient aspects of your data. \n\n\n::: {.callout-tip}\n**NOTE (IMPORTANT CONCEPT)** \n\nDimensionality reduction techniques (such as PCA) always lose some information. In other words, it is *lossy*.\n:::\n<!-- end callout -->\n\n\n\n\n### Lesson on lossy compression (PCA applied to image)\n\n### Learning Objectives\n\n* Understand how Principal Component Analysis (PCA) can be applied to images.\n* Observe how PCA captures the most significant patterns in image data.\n* Visualize how the number of principal components affects image reconstruction.\n* Appreciate the trade-off between compression and information loss.\n\n### Key Concepts\n\n* **PCA** is a dimensionality reduction technique that identifies directions (principal components) along which the variance in the data is maximized.\n* Images can be viewed as high-dimensional data (each pixel as a feature), and PCA helps reduce that dimensionality while preserving key patterns.\n\n### Procedure Overview\n\n1. **Load and display an image** from a URL.\n2. **Apply PCA to each RGB channel** of the image separately.\n3. **Reconstruct the image** using an increasing number of principal components.\n4. **Visualize the reconstructions** to show how few components capture most of the image's structure.\n\n::: {#43497bb2 .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](walkthrough_files/figure-html/cell-7-output-1.png){width=296 height=409}\n:::\n\n::: {.cell-output .cell-output-display}\n![](walkthrough_files/figure-html/cell-7-output-2.png){width=1430 height=447}\n:::\n:::\n\n\n### Takeaway Message\n\nPCA can significantly reduce image data dimensionality while preserving salient features, making it a powerful tool for image compression and understanding. However, perfect reconstruction is only possible with all components, revealing the balance between efficiency and fidelity.\n\n\n\n::: {.callout-tip}\n### Key Concept \n\n![Information bottleneck](images/information_bottleneck.png)\n\n\nIn unsupervised learning, the __bottleneck concept__ refers to a deliberate  constraint where information is compressed through a narrow intermediate step. The model is trained to reconstruct the input data after passing it through this low-dimensional bottleneck, forcing it to learn a compact and informative representation of the underlying structure of the data. \n\n\n_Note_: The figure shows features coming in from the right and getting compressed to fewer (new) features. What is not shown is that there are multiple rows in the dataset.\n\nSince there are no labels guiding the learning process, the model relies solely on reconstructing its input as accurately as possible, using only the limited information passed through this narrow channel. This compression encourages the model to capture essential features while discarding noise or redundancy.\n\n\n<!--\nThe bottleneck acts as an inductive bias that promotes dimensionality reduction, feature learning, and denoising. By minimizing reconstruction error while constrained by a reduced latent space, the model implicitly discovers patterns, clusters, and hierarchies within the input data. In practical terms, this is a foundational principle behind many unsupervised representation learning methods, including classical autoencoders, variational autoencoders (VAEs), and self-supervised learning systems that rely on contrastive or generative objectives. The learned low-dimensional codes can then be used for downstream tasks such as clustering, visualization (e.g., with t-SNE or PCA), or as inputs to supervised models in a semi-supervised setting.\n\nmagine you have a huge library of biological images—say, pictures of different cell types under a microscope—and you want to teach a computer to recognize patterns in those images without telling it what any of the cells are. A “bottleneck” in this context is like asking the computer to summarize each image using only a few key words instead of the entire picture. By forcing it to compress all the rich detail down to a small summary, the computer has to figure out which features—like cell shape, size, or texture—are truly important. This is similar to how a biologist might sketch a simplified diagram of a cell, highlighting its nucleus and membrane but leaving out every ribosome and microtubule.\n-->\n\nBecause the computer must recreate the original image from that stripped‑down summary, it learns to ignore random noise.\n\n<!--\n or unimportant quirks (like slight variations in lighting) and focus on the core characteristics shared by similar cell types. In other words, the bottleneck helps the machine discover the hidden “essence” of the data. \n-->\n\n<!--\nOnce you have those concise summaries, you can use them to cluster cells into groups, visualize how different cell types relate, or even feed them into a second analysis—just as you might reduce a complex DNA dataset to a handful of genetic markers before drawing a phylogenetic tree. This approach lets you explore and interpret large biological datasets more effectively, all without ever providing explicit labels.\n-->\n:::\n<!-- end callout -->\n\n\n\n::: {.callout-tip}\n## Activity: Playable version of PCA in browser\n\n[PCA in your browser](https://projector.tensorflow.org/)\n:::\n<!-- end callout -->\n\n\n## Visual explanations of PCA\n\n::: {#9fdd0ceb .cell fig.cap='Visual explanation of PCA' execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](walkthrough_files/figure-html/cell-8-output-1.png){width=662 height=523}\n:::\n:::\n\n\n::: {.callout-tip}\n## Intuition\n\n* PCA maximimizes the variance captured\n\n::: {#0ca416e7 .cell fig.cap='Intuition behind PCA' execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](walkthrough_files/figure-html/cell-9-output-1.png){width=651 height=671}\n:::\n:::\n\n\n* App to explain the intuition behind PCA\n\n![Animation](images/pca_rotating_clean.gif)\n\n![Animation](images/pca_pendulum_animation.gif)\n\n\n\n:::\n<!-- end callout -->\n\n\n\n## Lesson Summary\n\n* Basics of unsupervised learning\n\n* Useful for visualization, outlier detection and making sense of your data if there are many features\n\n- **What it is:** Discover hidden patterns or groupings in unlabeled data, without predicting a specific target.  \n- **Key techniques:**  \n  - **Clustering** for grouping similar observations  \n  - **Dimensionality reduction** (e.g. PCA) for compressing and visualizing high‑dimensional data  \n- **Why it matters:**  \n  - Reveals structure in customer segmentation, anomaly detection, image compression, etc.  \n  - Serves as exploratory analysis and preprocessing for downstream tasks  \n- **Information bottleneck:** Forcing models to squeeze data through a narrow bottleneck uncovers the most essential features and removes noise  \n- **Hands‑on example:** Apply PCA to crime‑and‑population data by state to project three features into two dimensions for visualization  \n- **Unsupervised vs. supervised:**  \n  - **Unsupervised:** No labels, focus on pattern discovery  \n  - **Supervised:** With _labels_, focus on _predicting_ a known outcome \n\n\n\n\n\n## Resources\n\n- [Introduction to Statistical Learning in Python book](https://www.statlearning.com/)\n\n- [Video lectures by the authors of the book Introduction to Statistical Learning in Python](https://www.youtube.com/playlist?list=PLoROMvodv4rNHU1-iPeDRH-J0cL-CrIda)\n\n- [Github repository with more theoretical material](https://github.com/neelsoumya/public_teaching_unsupervised_learning)\n\n- [Interactive explanations of machine learning models](https://mlu-explain.github.io)\n\n- [Mathematics behind unsupervised machine learning](https://mml-book.github.io/book/mml-book.pdf)\n\n",
    "supporting": [
      "walkthrough_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}